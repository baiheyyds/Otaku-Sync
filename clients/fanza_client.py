# clients/fanza_client.py
import logging
import re
from typing import Any, Dict, List
from urllib.parse import quote, urljoin

from bs4 import BeautifulSoup, Tag

from .base_client import BaseClient


class FanzaClient(BaseClient):
    def __init__(self, client):
        super().__init__(client, base_url="https://dlsoft.dmm.co.jp")
        self.cookies = {"age_check_done": "1"}

    async def search(self, keyword: str, limit=30):
        logging.info(f"ğŸ” [Fanza] å¼€å§‹ä¸»æœç´¢ (dlsoft): {keyword}")
        try:
            # --- ä¸»æœç´¢é€»è¾‘ (ä½¿ç”¨ dlsoft) ---
            encoded_keyword = quote(keyword.encode("utf-8", errors="ignore"))
            url = f"/search/?service=pcgame&searchstr={encoded_keyword}&sort=date"
            resp = await self.get(url, timeout=15, cookies=self.cookies)

            results = []
            if resp:
                soup = BeautifulSoup(resp.text, "lxml")
                result_list = soup.select_one("ul.component-legacy-productTile")
                if result_list:
                    for li in result_list.find_all("li", class_="component-legacy-productTile__item", limit=limit):
                        if not isinstance(li, Tag):
                            continue
                        title_tag = li.select_one(".component-legacy-productTile__title")
                        price_tag = li.select_one(".component-legacy-productTile__price")
                        url_tag = li.select_one("a.component-legacy-productTile__detailLink")
                        type_tag = li.select_one(".component-legacy-productTile__relatedInfo")
                        item_type = type_tag.get_text(strip=True) if type_tag else "æœªçŸ¥"

                        if not (title_tag and url_tag):
                            continue

                        href = url_tag.get("href")
                        if not isinstance(href, str):
                            continue

                        title = title_tag.get_text(strip=True)
                        price_text = price_tag.get_text(strip=True) if price_tag else "æœªçŸ¥"
                        price = price_text.split("å††")[0].replace(",", "").strip()
                        full_url = urljoin(self.base_url, href)

                        thumbnail_url = None
                        img_tag = li.select_one(".component-legacy-productTile__thumbnail img")
                        if img_tag:
                            thumbnail_url = img_tag.get('data-src') or img_tag.get('src')

                        results.append({
                            "title": title, "url": full_url,
                            "ä»·æ ¼": price or "æœªçŸ¥", "ç±»å‹": item_type,
                            "thumbnail_url": thumbnail_url,
                        })

            # --- ç­›é€‰ä¸»æœç´¢ç»“æœ ---
            initial_count = len(results)
            filtered_results = [item for item in results if "ã‚²ãƒ¼ãƒ " in item.get("ç±»å‹", "")]
            exclude_keywords = ["éŸ³æ¥½", "ä¸»é¡Œæ­Œ"]
            filtered_results = [
                item for item in filtered_results
                if not any(ex in item.get("title", "") for ex in exclude_keywords)
            ]
            final_count = len(filtered_results)

            if final_count > 0:
                logging.info(f"âœ… [Fanza] ä¸»æœç´¢æˆåŠŸï¼Œæ‰¾åˆ° {initial_count} ä¸ªåŸå§‹ç»“æœï¼Œç­›é€‰åå‰©ä½™ {final_count} ä¸ªæ¸¸æˆã€‚")
                return filtered_results

            # --- åå¤‡æœç´¢é€»è¾‘ (å¦‚æœä¸»æœç´¢æ— ç»“æœ) ---
            logging.warning("âš ï¸ [Fanza] ä¸»æœç´¢ (dlsoft) æœªæ‰¾åˆ°ç»“æœï¼Œå°è¯•åå¤‡æœç´¢ (mono)...")

            fallback_base_url = "https://www.dmm.co.jp"
            url_fallback = f"{fallback_base_url}/mono/-/search/=/searchstr={encoded_keyword}/sort=date/"

            resp_fallback = await self.get(url_fallback, timeout=15, cookies=self.cookies)
            if not resp_fallback:
                logging.error("âŒ [Fanza] åå¤‡æœç´¢è¯·æ±‚å¤±è´¥ã€‚")
                return []

            soup_fallback = BeautifulSoup(resp_fallback.text, "lxml")
            results_fallback = []
            result_list_fallback = soup_fallback.select_one("#list")
            if not result_list_fallback:
                logging.warning("âš ï¸ [Fanza] åå¤‡æœç´¢æœªæ‰¾åˆ°ç»“æœåˆ—è¡¨ (#list)ã€‚")
                return []

            for li in result_list_fallback.find_all("li", limit=limit):
                if not isinstance(li, Tag):
                    continue
                url_tag = li.select_one(".tmb a")
                if not url_tag: continue

                title_tag = url_tag.select_one(".txt")
                price_tag = li.select_one(".price")

                if not (title_tag and url_tag): continue

                href = url_tag.get("href")
                if not isinstance(href, str):
                    continue

                title = title_tag.get_text(strip=True)
                price_text = price_tag.get_text(strip=True) if price_tag else "æœªçŸ¥"
                price = price_text.split("å††")[0].replace(",", "").strip()
                full_url = urljoin(fallback_base_url, href)

                thumbnail_url = None
                img_tag = url_tag.select_one("img")
                if img_tag:
                    thumbnail_url = img_tag.get('data-src') or img_tag.get('src')

                results_fallback.append({
                    "title": title, "url": full_url,
                    "ä»·æ ¼": price or "æœªçŸ¥", "ç±»å‹": "æœªçŸ¥(åå¤‡)",
                    "thumbnail_url": thumbnail_url,
                })

            initial_count_fallback = len(results_fallback)
            filtered_results_fallback = [
                item for item in results_fallback
                if not any(ex in item.get("title", "") for ex in exclude_keywords)
            ]
            final_count_fallback = len(filtered_results_fallback)
            logging.info(f"âœ… [Fanza] åå¤‡æœç´¢æˆåŠŸï¼Œæ‰¾åˆ° {initial_count_fallback} ä¸ªåŸå§‹ç»“æœï¼Œç­›é€‰åå‰©ä½™ {final_count_fallback} ä¸ªã€‚")
            return filtered_results_fallback

        except Exception as e:
            logging.error(f"âŒ [Fanza] æœç´¢è¿‡ç¨‹ä¸­å‡ºç°æ„å¤–é”™è¯¯: {e}")
            return []

    async def get_game_detail(self, url: str) -> dict:
        logging.info(f"â³ [Fanza] æ­£åœ¨æŠ“å–æ¸¸æˆè¯¦æƒ…é¡µé¢ï¼Œè¯·ç¨å€™... URL: {url}")
        resp = await self.get(url, timeout=15, cookies=self.cookies)
        if not resp:
            return {}

        try:
            soup = BeautifulSoup(resp.text, "lxml")
            details: Dict[str, Any] = {}
            game_types: List[str] = []

            # ==================================================================
            # æ™ºèƒ½è§£æï¼šæ ¹æ®URLåˆ¤æ–­ä½¿ç”¨å“ªå¥—è§£æé€»è¾‘
            # ==================================================================
            if "/mono/" in url:
                # --- æ—§ç‰ˆ/åå¤‡æ¥å£ (`/mono/`) çš„è§£æé€»è¾‘ ---
                logging.info("ğŸ” [Fanza] æ£€æµ‹åˆ° /mono/ é“¾æ¥ï¼Œä½¿ç”¨æ—§ç‰ˆè¡¨æ ¼è§£æå™¨ã€‚")

                if title_tag := soup.select_one("h1#title"):
                    details["æ ‡é¢˜"] = title_tag.get_text(strip=True)

                if cover_tag := soup.select_one("#sample-video img, .area-img img"):
                     if src := cover_tag.get("src"):
                        if isinstance(src, str):
                            details["å°é¢å›¾é“¾æ¥"] = urljoin(self.base_url, src)

                if main_table := soup.select_one("table.mg-b20"):
                    rows = main_table.find_all("tr")
                    for row in rows:
                        if not isinstance(row, Tag):
                            continue
                        cells = row.find_all("td")
                        if len(cells) < 2: continue

                        key = cells[0].get_text(strip=True)
                        value_cell = cells[1]

                        if "ç™ºå£²æ—¥" in key:
                            details["å‘å”®æ—¥"] = value_cell.get_text(strip=True)
                        elif "ãƒ–ãƒ©ãƒ³ãƒ‰" in key:
                            details["å“ç‰Œ"] = value_cell.get_text(strip=True)
                        elif "åŸç”»" in key:
                            details["åŸç”»"] = [a.get_text(strip=True) for a in value_cell.find_all("a")]
                        elif "ã‚·ãƒŠãƒªã‚ª" in key:
                            details["å‰§æœ¬"] = [a.get_text(strip=True) for a in value_cell.find_all("a")]
                        elif key.startswith("ã‚¸ãƒ£ãƒ³ãƒ«"):
                            details["æ ‡ç­¾"] = [a.get_text(strip=True) for a in value_cell.find_all("a")]
                        elif "ã‚²ãƒ¼ãƒ ã‚¸ãƒ£ãƒ³ãƒ«" in key:
                            genre_text = value_cell.get_text(strip=True).upper()
                            for genre_key, genre_value in self._genre_reverse_mapping.items():
                                if genre_key in genre_text: game_types.append(genre_value)
                        elif "ãƒœã‚¤ã‚¹" in key:
                            if "ã‚ã‚Š" in value_cell.get_text(strip=True):
                                game_types = details.get("ä½œå“å½¢å¼", [])
                                game_types.extend(["æœ‰å£°éŸ³", "æœ‰éŸ³ä¹"])
                                details["ä½œå“å½¢å¼"] = list(dict.fromkeys(game_types))
            else:
                # --- æ–°ç‰ˆ/ä¸»æ¥å£ (`dlsoft`) çš„è§£æé€»è¾‘ (ç°æœ‰é€»è¾‘) ---
                logging.info("ğŸ” [Fanza] æœªæ£€æµ‹åˆ° /mono/ é“¾æ¥ï¼Œä½¿ç”¨æ–°ç‰ˆè§£æå™¨ã€‚")
                if top_table := soup.select_one(".contentsDetailTop__table"):
                    for row in top_table.find_all("div", class_="contentsDetailTop__tableRow"):
                        if not isinstance(row, Tag):
                            continue
                        key_tag = row.select_one(".contentsDetailTop__tableDataLeft p")
                        value_tag = row.select_one(".contentsDetailTop__tableDataRight")
                        if not (key_tag and value_tag): continue
                        if "ãƒ–ãƒ©ãƒ³ãƒ‰" in key_tag.get_text(strip=True):
                            details["å“ç‰Œ"] = value_tag.get_text(strip=True)

                if bottom_table := soup.select_one(".contentsDetailBottom__table"):
                    def find_row_value(header_text: str) -> Tag | None:
                        p_tag = bottom_table.find("p", string=re.compile(f"^{header_text}$"))
                        if p_tag and (parent_div := p_tag.find_parent("div")):
                            return parent_div.find_next_sibling("div")
                        return None

                    if value_div := find_row_value("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç‰ˆé…ä¿¡é–‹å§‹æ—¥"):
                        date_span = value_div.select_one(".item-info__release-date__content__date span")
                        date_text = (date_span.get_text(strip=True) if date_span else value_div.get_text(strip=True))
                        if date_text: details["å‘å”®æ—¥"] = date_text

                    def extract_list(value_div: Tag | None) -> list[str]:
                        if not value_div: return []
                        return [a.get_text(strip=True) for a in value_div.select("li a")]

                    for key, value in self.STAFF_MAPPING.items():
                        if key == "ã‚¤ãƒ©ã‚¹ãƒˆ": continue
                        extracted_data = extract_list(find_row_value(key))
                        if extracted_data:
                            if value in details: details[value].extend(extracted_data)
                            else: details[value] = extracted_data

                    for key in details:
                        if isinstance(details[key], list): details[key] = sorted(list(set(details[key])))

                    if genre_div := find_row_value("ã‚²ãƒ¼ãƒ ã‚¸ãƒ£ãƒ³ãƒ«"):
                        genre_text = genre_div.get_text(strip=True).upper()
                        for key, value in self._genre_reverse_mapping.items():
                            if key in genre_text: game_types.append(value)

                    if voice_div := find_row_value("ãƒœã‚¤ã‚¹"):
                        if "ã‚ã‚Š" in voice_div.get_text(strip=True): game_types.extend(["æœ‰å£°éŸ³", "æœ‰éŸ³ä¹"])

                    if game_types: details["ä½œå“å½¢å¼"] = list(dict.fromkeys(game_types))

                    if tags_div := find_row_value("ã‚¸ãƒ£ãƒ³ãƒ«"):
                        details["æ ‡ç­¾"] = [a.get_text(strip=True) for a in tags_div.select("li a")]

                if cover_tag := soup.find("meta", property="og:image"):
                    details["å°é¢å›¾é“¾æ¥"] = urljoin(self.base_url, cover_tag["content"])
                else:
                    cover_selector = (".productPreview__mainImage img, #fn-main_image, .main-visual img")
                    if cover_img_tag := soup.select_one(cover_selector):
                        if src := cover_img_tag.get("src"): details["å°é¢å›¾é“¾æ¥"] = urljoin(self.base_url, src)

                if title_tag := soup.select_one("h1.productTitle__txt"):
                    details["æ ‡é¢˜"] = title_tag.get_text(strip=True)
                if price_tag := soup.select_one(".priceInformation__price"):
                    details["ä»·æ ¼"] = price_tag.get_text(strip=True).replace("å††", "").replace(",", "")

            if game_types:
                details["ä½œå“å½¢å¼"] = sorted(list(dict.fromkeys(game_types)))

            return details
        except Exception as e:
            logging.error(f"âŒ [Fanza] è§£æè¯¦æƒ…é¡µå¤±è´¥: {e}")
            return {}
